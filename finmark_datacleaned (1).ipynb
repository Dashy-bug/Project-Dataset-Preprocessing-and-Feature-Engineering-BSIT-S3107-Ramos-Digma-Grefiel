{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2dbff24-77f0-43ee-9b12-5cc8cb7fa2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes:\n",
      "Feedback: (5050, 4)\n",
      "Products: (15, 6)\n",
      "Transactions: (5050, 5)\n",
      "\n",
      "✅ Saved outputs to: C:\\Users\\lawre\\Downloads\\finmark_outputs\n",
      " - FinMark_Customer_Features.csv shape: (993, 20)\n",
      " - FinMark_Transaction_Enriched.csv shape: (4900, 8)\n",
      " - FinMark_Product_Cleaned.csv shape: (10, 6)\n",
      " - FinMark_Feedback_Cleaned.csv shape: (4969, 4)\n",
      " - FinMark_Preprocessing_Notes.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Total_Transactions</th>\n",
       "      <th>Total_Spend</th>\n",
       "      <th>Avg_Transaction_Value</th>\n",
       "      <th>Max_Transaction_Value</th>\n",
       "      <th>Min_Transaction_Value</th>\n",
       "      <th>Spend_Volatility</th>\n",
       "      <th>First_Transaction_Date</th>\n",
       "      <th>Last_Transaction_Date</th>\n",
       "      <th>Recency_Days</th>\n",
       "      <th>Customer_Lifetime_Days</th>\n",
       "      <th>Spend_Per_Day</th>\n",
       "      <th>Transactions_Per_Month</th>\n",
       "      <th>Max_to_Avg_Ratio</th>\n",
       "      <th>Share_Bill_Payment</th>\n",
       "      <th>Share_Investment</th>\n",
       "      <th>Share_Loan_Payment</th>\n",
       "      <th>Share_Purchase</th>\n",
       "      <th>Feedback_Count</th>\n",
       "      <th>Is_Silent_Customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16836.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>4993.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2062.310646</td>\n",
       "      <td>2023-01-02 04:00:00</td>\n",
       "      <td>2023-07-02 03:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>180</td>\n",
       "      <td>93.533333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.779401</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4907.0</td>\n",
       "      <td>2453.5</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>560.735677</td>\n",
       "      <td>2023-02-06 04:00:00</td>\n",
       "      <td>2023-05-21 23:00:00</td>\n",
       "      <td>67</td>\n",
       "      <td>104</td>\n",
       "      <td>47.182692</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>1.161606</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-27 23:00:00</td>\n",
       "      <td>2023-02-27 23:00:00</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1538.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8295.0</td>\n",
       "      <td>4147.5</td>\n",
       "      <td>4736.0</td>\n",
       "      <td>3559.0</td>\n",
       "      <td>832.264681</td>\n",
       "      <td>2023-01-22 15:00:00</td>\n",
       "      <td>2023-06-30 01:00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>158</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>1.141893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14798.0</td>\n",
       "      <td>2959.6</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>1386.584040</td>\n",
       "      <td>2023-02-19 15:00:00</td>\n",
       "      <td>2023-07-27 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>94.254777</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>1.648196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_ID  Total_Transactions  Total_Spend  Avg_Transaction_Value  \\\n",
       "0            1                   6      16836.0                 2806.0   \n",
       "1            2                   2       4907.0                 2453.5   \n",
       "2            3                   1       1538.0                 1538.0   \n",
       "3            4                   2       8295.0                 4147.5   \n",
       "4            5                   5      14798.0                 2959.6   \n",
       "\n",
       "   Max_Transaction_Value  Min_Transaction_Value  Spend_Volatility  \\\n",
       "0                 4993.0                  156.0       2062.310646   \n",
       "1                 2850.0                 2057.0        560.735677   \n",
       "2                 1538.0                 1538.0               NaN   \n",
       "3                 4736.0                 3559.0        832.264681   \n",
       "4                 4878.0                 1508.0       1386.584040   \n",
       "\n",
       "  First_Transaction_Date Last_Transaction_Date  Recency_Days  \\\n",
       "0    2023-01-02 04:00:00   2023-07-02 03:00:00            26   \n",
       "1    2023-02-06 04:00:00   2023-05-21 23:00:00            67   \n",
       "2    2023-02-27 23:00:00   2023-02-27 23:00:00           150   \n",
       "3    2023-01-22 15:00:00   2023-06-30 01:00:00            28   \n",
       "4    2023-02-19 15:00:00   2023-07-27 00:00:00             1   \n",
       "\n",
       "   Customer_Lifetime_Days  Spend_Per_Day  Transactions_Per_Month  \\\n",
       "0                     180      93.533333                1.000000   \n",
       "1                     104      47.182692                0.576923   \n",
       "2                       1    1538.000000               30.000000   \n",
       "3                     158      52.500000                0.379747   \n",
       "4                     157      94.254777                0.955414   \n",
       "\n",
       "   Max_to_Avg_Ratio  Share_Bill_Payment  Share_Investment  Share_Loan_Payment  \\\n",
       "0          1.779401                 0.5          0.166667            0.166667   \n",
       "1          1.161606                 0.5          0.000000            0.500000   \n",
       "2          1.000000                 1.0          0.000000            0.000000   \n",
       "3          1.141893                 0.0          0.000000            0.500000   \n",
       "4          1.648196                 0.4          0.200000            0.000000   \n",
       "\n",
       "   Share_Purchase  Feedback_Count  Is_Silent_Customer  \n",
       "0        0.166667               2                   0  \n",
       "1        0.000000               3                   0  \n",
       "2        0.000000               3                   0  \n",
       "3        0.500000               6                   0  \n",
       "4        0.400000               9                   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FinMark: End-to-end Cleaning + Feature Engineering + Export\n",
    "# Local JupyterLab (Windows) safe, with /mnt/data fallback\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Optional: opt-in to future behavior (prevents silent downcasting issues)\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Paths (EDIT if needed)\n",
    "# ----------------------------\n",
    "feedback_path_win     = r\"C:\\Users\\lawre\\Downloads\\Customer_Feedback_Data.csv\"\n",
    "product_path_win      = r\"C:\\Users\\lawre\\Downloads\\Product_Offering_Data.csv\"\n",
    "transaction_path_win  = r\"C:\\Users\\lawre\\Downloads\\Transaction_Data.csv\"\n",
    "\n",
    "# Optional fallback (for hosted/sandbox environments)\n",
    "feedback_path_fb      = \"/mnt/data/Customer_Feedback_Data.csv\"\n",
    "product_path_fb       = \"/mnt/data/Product_Offering_Data.csv\"\n",
    "transaction_path_fb   = \"/mnt/data/Transaction_Data.csv\"\n",
    "\n",
    "def pick_path(primary, fallback):\n",
    "    if os.path.exists(primary): return primary\n",
    "    if os.path.exists(fallback): return fallback\n",
    "    raise FileNotFoundError(f\"File not found:\\n- {primary}\\n- {fallback}\")\n",
    "\n",
    "feedback_path    = pick_path(feedback_path_win, feedback_path_fb)\n",
    "product_path     = pick_path(product_path_win, product_path_fb)\n",
    "transaction_path = pick_path(transaction_path_win, transaction_path_fb)\n",
    "\n",
    "# Output folder (Windows-safe)\n",
    "out_dir = Path.home() / \"Downloads\" / \"finmark_outputs\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load\n",
    "# ----------------------------\n",
    "fb_raw   = pd.read_csv(feedback_path)\n",
    "prod_raw = pd.read_csv(product_path)\n",
    "tx_raw   = pd.read_csv(transaction_path)\n",
    "\n",
    "print(\"Loaded shapes:\")\n",
    "print(\"Feedback:\", fb_raw.shape)\n",
    "print(\"Products:\", prod_raw.shape)\n",
    "print(\"Transactions:\", tx_raw.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Helpers\n",
    "# ----------------------------\n",
    "notes = []\n",
    "\n",
    "def std_title(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Standardize categorical text:\n",
    "    - Use pandas StringDtype (prevents downcasting warnings)\n",
    "    - Strip, Title-case\n",
    "    - Replace common null tokens with pd.NA\n",
    "    \"\"\"\n",
    "    s = series.astype(\"string\")\n",
    "    s = s.str.strip().str.title()\n",
    "    s = s.replace([\"Nan\", \"None\", \"Na\", \"N/A\", \"Null\", \"\"], pd.NA)\n",
    "    return s\n",
    "\n",
    "def safe_numeric(series: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(series, errors=\"coerce\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Clean + Standardize\n",
    "# ----------------------------\n",
    "\n",
    "# ---- Transactions ----\n",
    "tx = tx_raw.copy()\n",
    "\n",
    "# Deduplicate\n",
    "if \"Transaction_ID\" in tx.columns:\n",
    "    before = len(tx)\n",
    "    tx = tx.drop_duplicates(subset=[\"Transaction_ID\"])\n",
    "    notes.append(f\"Dropped {before-len(tx)} duplicate Transaction_ID rows.\")\n",
    "else:\n",
    "    before = len(tx)\n",
    "    tx = tx.drop_duplicates()\n",
    "    notes.append(f\"Dropped {before-len(tx)} fully-duplicate transaction rows (no Transaction_ID).\")\n",
    "\n",
    "# Standardize date\n",
    "if \"Transaction_Date\" in tx.columns:\n",
    "    tx[\"Transaction_Date\"] = pd.to_datetime(tx[\"Transaction_Date\"], errors=\"coerce\")\n",
    "    bad_dates = tx[\"Transaction_Date\"].isna().sum()\n",
    "    if bad_dates:\n",
    "        notes.append(f\"Transaction_Date: {bad_dates} invalid dates set to NaT (coerced).\")\n",
    "else:\n",
    "    notes.append(\"WARNING: Transaction_Date column not found. Time-based features limited.\")\n",
    "\n",
    "# Standardize amount (required)\n",
    "if \"Transaction_Amount\" in tx.columns:\n",
    "    tx[\"Transaction_Amount\"] = safe_numeric(tx[\"Transaction_Amount\"])\n",
    "    before = len(tx)\n",
    "    tx = tx.dropna(subset=[\"Transaction_Amount\"])\n",
    "    notes.append(f\"Dropped {before-len(tx)} rows with missing/invalid Transaction_Amount.\")\n",
    "else:\n",
    "    raise KeyError(\"Transaction_Data must contain Transaction_Amount.\")\n",
    "\n",
    "# Standardize transaction type\n",
    "if \"Transaction_Type\" in tx.columns:\n",
    "    tx[\"Transaction_Type\"] = std_title(tx[\"Transaction_Type\"])\n",
    "\n",
    "# Key checks\n",
    "if \"Customer_ID\" not in tx.columns:\n",
    "    raise KeyError(\"Transaction_Data must contain Customer_ID.\")\n",
    "\n",
    "# ---- Products ----\n",
    "prod = prod_raw.copy()\n",
    "\n",
    "if \"Product_ID\" in prod.columns:\n",
    "    before = len(prod)\n",
    "    prod = prod.drop_duplicates(subset=[\"Product_ID\"])\n",
    "    notes.append(f\"Dropped {before-len(prod)} duplicate Product_ID rows.\")\n",
    "else:\n",
    "    before = len(prod)\n",
    "    prod = prod.drop_duplicates()\n",
    "    notes.append(f\"Dropped {before-len(prod)} fully-duplicate product rows (no Product_ID).\")\n",
    "\n",
    "for c in [\"Product_Name\", \"Product_Type\", \"Risk_Level\", \"Target_Age_Group\", \"Target_Income_Group\"]:\n",
    "    if c in prod.columns:\n",
    "        prod[c] = std_title(prod[c])\n",
    "\n",
    "if \"Target_Age_Group\" in prod.columns:\n",
    "    miss = prod[\"Target_Age_Group\"].isna().sum()\n",
    "    if miss:\n",
    "        prod[\"Target_Age_Group\"] = prod[\"Target_Age_Group\"].fillna(\"All\")\n",
    "        notes.append(f\"Filled {miss} missing Target_Age_Group with 'All'.\")\n",
    "\n",
    "# ---- Feedback ----\n",
    "fb = fb_raw.copy()\n",
    "\n",
    "if \"Feedback_ID\" in fb.columns:\n",
    "    before = len(fb)\n",
    "    fb = fb.drop_duplicates(subset=[\"Feedback_ID\"])\n",
    "    notes.append(f\"Dropped {before-len(fb)} duplicate Feedback_ID rows.\")\n",
    "else:\n",
    "    before = len(fb)\n",
    "    fb = fb.drop_duplicates()\n",
    "    notes.append(f\"Dropped {before-len(fb)} fully-duplicate feedback rows (no Feedback_ID).\")\n",
    "\n",
    "if \"Feedback_Date\" in fb.columns:\n",
    "    fb[\"Feedback_Date\"] = pd.to_datetime(fb[\"Feedback_Date\"], errors=\"coerce\")\n",
    "    bad = fb[\"Feedback_Date\"].isna().sum()\n",
    "    if bad:\n",
    "        notes.append(f\"Feedback_Date: {bad} invalid dates set to NaT (coerced).\")\n",
    "\n",
    "if \"Sentiment\" in fb.columns:\n",
    "    fb[\"Sentiment\"] = std_title(fb[\"Sentiment\"])\n",
    "\n",
    "if \"Rating\" in fb.columns:\n",
    "    fb[\"Rating\"] = safe_numeric(fb[\"Rating\"])\n",
    "\n",
    "# Customer_ID in feedback is optional (features will be skipped if missing)\n",
    "feedback_has_customer = \"Customer_ID\" in fb.columns\n",
    "if not feedback_has_customer:\n",
    "    notes.append(\"WARNING: Feedback has no Customer_ID; feedback features will be skipped.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Feature Engineering (FinMark)\n",
    "# ----------------------------\n",
    "\n",
    "# Row-level time features\n",
    "if \"Transaction_Date\" in tx.columns:\n",
    "    tx[\"Tx_Month\"] = tx[\"Transaction_Date\"].dt.month\n",
    "    tx[\"Tx_Year\"]  = tx[\"Transaction_Date\"].dt.year\n",
    "    tx[\"Tx_DayOfWeek\"] = tx[\"Transaction_Date\"].dt.dayofweek  # 0=Mon\n",
    "\n",
    "# Customer-level transaction aggregates\n",
    "customer_tx = (\n",
    "    tx.groupby(\"Customer_ID\", as_index=False)\n",
    "      .agg(\n",
    "          Total_Transactions=(\"Transaction_Amount\", \"size\"),\n",
    "          Total_Spend=(\"Transaction_Amount\", \"sum\"),\n",
    "          Avg_Transaction_Value=(\"Transaction_Amount\", \"mean\"),\n",
    "          Max_Transaction_Value=(\"Transaction_Amount\", \"max\"),\n",
    "          Min_Transaction_Value=(\"Transaction_Amount\", \"min\"),\n",
    "          Spend_Volatility=(\"Transaction_Amount\", \"std\"),\n",
    "      )\n",
    ")\n",
    "\n",
    "# Recency / lifetime / intensity\n",
    "if \"Transaction_Date\" in tx.columns:\n",
    "    first_last = (\n",
    "        tx.groupby(\"Customer_ID\", as_index=False)\n",
    "          .agg(\n",
    "              First_Transaction_Date=(\"Transaction_Date\", \"min\"),\n",
    "              Last_Transaction_Date=(\"Transaction_Date\", \"max\"),\n",
    "          )\n",
    "    )\n",
    "    customer_tx = customer_tx.merge(first_last, on=\"Customer_ID\", how=\"left\")\n",
    "\n",
    "    reference_date = tx[\"Transaction_Date\"].max()\n",
    "    customer_tx[\"Recency_Days\"] = (reference_date - customer_tx[\"Last_Transaction_Date\"]).dt.days\n",
    "\n",
    "    customer_tx[\"Customer_Lifetime_Days\"] = (\n",
    "        (customer_tx[\"Last_Transaction_Date\"] - customer_tx[\"First_Transaction_Date\"]).dt.days\n",
    "        .clip(lower=1)\n",
    "    )\n",
    "\n",
    "    customer_tx[\"Spend_Per_Day\"] = customer_tx[\"Total_Spend\"] / customer_tx[\"Customer_Lifetime_Days\"]\n",
    "    customer_tx[\"Transactions_Per_Month\"] = (\n",
    "        customer_tx[\"Total_Transactions\"] / (customer_tx[\"Customer_Lifetime_Days\"] / 30.0)\n",
    "    )\n",
    "else:\n",
    "    notes.append(\"No Transaction_Date: skipped recency/lifetime/time-intensity features.\")\n",
    "\n",
    "# Spend concentration ratio\n",
    "customer_tx[\"Max_to_Avg_Ratio\"] = (\n",
    "    customer_tx[\"Max_Transaction_Value\"] /\n",
    "    customer_tx[\"Avg_Transaction_Value\"].replace(0, np.nan)\n",
    ")\n",
    "\n",
    "# Transaction-type behavior shares\n",
    "if \"Transaction_Type\" in tx.columns:\n",
    "    type_counts = (\n",
    "        tx.pivot_table(index=\"Customer_ID\", columns=\"Transaction_Type\",\n",
    "                       values=\"Transaction_Amount\", aggfunc=\"size\", fill_value=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "    type_cols = [c for c in type_counts.columns if c != \"Customer_ID\"]\n",
    "    type_counts[\"Type_Total\"] = type_counts[type_cols].sum(axis=1).replace({0: np.nan})\n",
    "\n",
    "    for c in type_cols:\n",
    "        safe = c.replace(\" \", \"_\")\n",
    "        type_counts[f\"Share_{safe}\"] = type_counts[c] / type_counts[\"Type_Total\"]\n",
    "\n",
    "    type_shares = type_counts[[\"Customer_ID\"] + [c for c in type_counts.columns if c.startswith(\"Share_\")]]\n",
    "    customer_tx = customer_tx.merge(type_shares, on=\"Customer_ID\", how=\"left\")\n",
    "else:\n",
    "    notes.append(\"Transaction_Type not found; skipped transaction-type share features.\")\n",
    "\n",
    "# Feedback-derived features\n",
    "customer_features = customer_tx.copy()\n",
    "\n",
    "if feedback_has_customer:\n",
    "    if \"Rating\" in fb.columns:\n",
    "        fb_agg = (\n",
    "            fb.groupby(\"Customer_ID\", as_index=False)\n",
    "              .agg(\n",
    "                  Avg_Rating=(\"Rating\", \"mean\"),\n",
    "                  Feedback_Count=(\"Rating\", \"size\"),\n",
    "              )\n",
    "        )\n",
    "    else:\n",
    "        fb_agg = fb.groupby(\"Customer_ID\", as_index=False).agg(Feedback_Count=(\"Customer_ID\", \"size\"))\n",
    "\n",
    "    # Sentiment shares\n",
    "    if \"Sentiment\" in fb.columns:\n",
    "        sent = (\n",
    "            fb.pivot_table(index=\"Customer_ID\", columns=\"Sentiment\",\n",
    "                           values=\"Customer_ID\", aggfunc=\"size\", fill_value=0)\n",
    "            .reset_index()\n",
    "        )\n",
    "        sent_cols = [c for c in sent.columns if c != \"Customer_ID\"]\n",
    "        sent[\"Sent_Total\"] = sent[sent_cols].sum(axis=1).replace({0: np.nan})\n",
    "        for c in sent_cols:\n",
    "            safe = c.replace(\" \", \"_\")\n",
    "            sent[f\"Share_{safe}_Sentiment\"] = sent[c] / sent[\"Sent_Total\"]\n",
    "\n",
    "        sent_shares = sent[[\"Customer_ID\"] + [c for c in sent.columns if c.endswith(\"_Sentiment\")]]\n",
    "        fb_agg = fb_agg.merge(sent_shares, on=\"Customer_ID\", how=\"left\")\n",
    "\n",
    "    customer_features = customer_features.merge(fb_agg, on=\"Customer_ID\", how=\"left\")\n",
    "\n",
    "    # Fill missing feedback values\n",
    "    if \"Feedback_Count\" in customer_features.columns:\n",
    "        customer_features[\"Feedback_Count\"] = customer_features[\"Feedback_Count\"].fillna(0)\n",
    "\n",
    "    if \"Avg_Rating\" in customer_features.columns:\n",
    "        customer_features[\"Avg_Rating\"] = customer_features[\"Avg_Rating\"].fillna(customer_features[\"Avg_Rating\"].mean())\n",
    "\n",
    "    customer_features[\"Is_Silent_Customer\"] = (customer_features.get(\"Feedback_Count\", 0) == 0).astype(int)\n",
    "else:\n",
    "    notes.append(\"Skipped feedback features (no Customer_ID in feedback file).\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Merge: transaction_enriched (tx + product attributes)\n",
    "# ----------------------------\n",
    "if \"Product_ID\" in tx.columns and \"Product_ID\" in prod.columns:\n",
    "    transaction_enriched = tx.merge(prod, on=\"Product_ID\", how=\"left\")\n",
    "else:\n",
    "    transaction_enriched = tx.copy()\n",
    "    notes.append(\"Product_ID missing in tx or prod; skipped tx-product merge (transaction_enriched=tx).\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Export\n",
    "# ----------------------------\n",
    "customer_features_path     = out_dir / \"FinMark_Customer_Features.csv\"\n",
    "transaction_enriched_path  = out_dir / \"FinMark_Transaction_Enriched.csv\"\n",
    "products_cleaned_path      = out_dir / \"FinMark_Product_Cleaned.csv\"\n",
    "feedback_cleaned_path      = out_dir / \"FinMark_Feedback_Cleaned.csv\"\n",
    "notes_path                 = out_dir / \"FinMark_Preprocessing_Notes.txt\"\n",
    "\n",
    "customer_features.to_csv(customer_features_path, index=False)\n",
    "transaction_enriched.to_csv(transaction_enriched_path, index=False)\n",
    "prod.to_csv(products_cleaned_path, index=False)\n",
    "fb.to_csv(feedback_cleaned_path, index=False)\n",
    "\n",
    "with open(notes_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"FinMark Preprocessing Notes\\n\")\n",
    "    f.write(\"=\"*30 + \"\\n\")\n",
    "    for n in notes:\n",
    "        f.write(f\"- {n}\\n\")\n",
    "\n",
    "print(\"\\n✅ Saved outputs to:\", out_dir)\n",
    "print(\" -\", customer_features_path.name, \"shape:\", customer_features.shape)\n",
    "print(\" -\", transaction_enriched_path.name, \"shape:\", transaction_enriched.shape)\n",
    "print(\" -\", products_cleaned_path.name, \"shape:\", prod.shape)\n",
    "print(\" -\", feedback_cleaned_path.name, \"shape:\", fb.shape)\n",
    "print(\" -\", notes_path.name)\n",
    "\n",
    "display(customer_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bfa64-17d8-42c2-8163-688883688d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
